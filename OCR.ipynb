{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction:\n",
    "The following project is an implementation of Optical character recognition.\n",
    "It uses the Tensorflow library to implement a Neural network which will be trained on the MNIST dataset to perform the desired operation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data(path = 'mnist.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input training set: (60000, 28, 28)\n",
      "Shape of label training set: (60000,)\n",
      "Shape of input test set: (10000, 28, 28)\n",
      "Shape of label test set: (10000,)\n",
      "Number of training examples: 60000\n",
      "Number of test examples: 10000\n",
      "Each image is of size: (28, 28)\n"
     ]
    }
   ],
   "source": [
    "Xtrain_shape = X_train.shape\n",
    "Ytrain_shape = y_train.shape\n",
    "Xtest_shape = X_test.shape\n",
    "Ytest_shape = y_test.shape\n",
    "m_train = Xtrain_shape[0]\n",
    "num_px = Xtrain_shape[1]\n",
    "m_test = Xtest_shape[0]\n",
    "\n",
    "print('Shape of input training set:',Xtrain_shape)\n",
    "print('Shape of label training set:',Ytrain_shape)\n",
    "print('Shape of input test set:',Xtest_shape)\n",
    "print('Shape of label test set:',Ytest_shape)\n",
    "print('Number of training examples:', m_train)\n",
    "print('Number of test examples:', m_test)\n",
    "print('Each image is of size: (' + str(num_px) + ', ' + str(num_px) + ')')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the output of the previous cell, the training set consists of a total of 70,000 images which have been split into two parts: The training set and the test set.\n",
    "The training set consists of 60,000 images and will be used to train the neural network and the test set will be used to evaluate the performance of the neural network once it has been trained. Each image of the training set has the dimensions (28,28). Let us look at the plots of some of the images to understand how the data to the neural network looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16328th image in training set is the number 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25632927208>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = random.randint(0,60000)\n",
    "print('{}th image in training set is the number {}'.format(index, y_train[index]))\n",
    "plt.imshow(X_train[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper class for handling callbacks:\n",
    "In the following cell, we define a class myCallback which will be used to handle callbacks from during the training process. In the context of this project, it will be used to check whether the neural network that we are training has achieved a certain level of accuracy. If it has, we can stop the training process as we have achieved our desired accuracy. Let us assume that we can stop the training process if we achieve an accuracy score of 99% or higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs = {}):\n",
    "        if (logs.get('accuracy') is not None and logs.get('accuracy') > 0.99):\n",
    "            print('\\nReached accuracy of 99%. Stopping training process!')\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing the data:\n",
    "When we are working with big numbers, it is a good practice to normalize the data that we are working with so that it lies between 0 and 1. This ensures better performance of the neural network. Since we are working with image data, we know that the values of the pixels lies between 0 and 255. Hence, by dividing the training and test data with the number 255, we can normalize our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the neural network:\n",
    "In the following section, we will define the structure of the neural network that we want to train. We will train neural networks with varying number of layers and neurons to compare the performances and choose the best one among them.\n",
    "We will start with a 2 layered neural network and go upto 4 layers.\n",
    "### Defining the 2 layered neural network:\n",
    "In the 2 layered neural network, the layers are the input and output layers. Hence, the number neurons in the input layer will be 784 because the size of the input images is (28 * 28). The output layer will contain 10 neurons because there are 10 digits, i.e 0-9 that we are trying to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoLayeredModel = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (28,28)),\n",
    "    tf.keras.layers.Dense(10, activation = tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the 3 layered neual network:\n",
    "In the 3 layered neural network, the  layers are the input, output and one hidden layer. The number of neurons in the input and output layers will be the same as the 2 layered neural network. The number of neurons in the hidden layer can be varied and hence, we will try the following number of neurons in the 3 layered neural network: 128, 256, 512 and 1024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "threeLayeredModel_1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (28,28)),\n",
    "    tf.keras.layers.Dense(128, activation = tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation = tf.nn.softmax)\n",
    "])\n",
    "\n",
    "threeLayeredModel_2 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (28,28)),\n",
    "    tf.keras.layers.Dense(256, activation = tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation = tf.nn.softmax)\n",
    "])\n",
    "\n",
    "threeLayeredModel_3 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (28,28)),\n",
    "    tf.keras.layers.Dense(512, activation = tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation = tf.nn.softmax)\n",
    "])\n",
    "\n",
    "threeLayeredModel_4 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (28,28)),\n",
    "    tf.keras.layers.Dense(1024, activation = tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation = tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the 4 layered neural network:\n",
    "In the 4 layered neural network, the number of neurons in the input and output layers will be the same as the 2 layered and 3 layered neural networks. The number of neurons in the 2 hidden layers can be varied. We will train the following 3 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourLayeredModel_1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (28, 28)),\n",
    "    tf.keras.layers.Dense(512, activation = tf.nn.relu),\n",
    "    tf.keras.layers.Dense(512, activation = tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation = tf.nn.softmax)\n",
    "])\n",
    "\n",
    "fourLayeredModel_2 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (28, 28)),\n",
    "    tf.keras.layers.Dense(256, activation = tf.nn.relu),\n",
    "    tf.keras.layers.Dense(768, activation = tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation = tf.nn.softmax)\n",
    "])\n",
    "\n",
    "fourLayeredModel_3 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation = tf.nn.relu),\n",
    "    tf.keras.layers.Dense(896, activation = tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation = tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the neural networks:\n",
    "As we have finished defining our neural networks, the next step is to compile the neural networks. Here, we will be defining the optimizer and loss functions for our neural networks. The optimizer function we are using is the adam optimizer function and the loss function we are using is the sparse_categorical_crossentropy function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoLayeredModel.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "threeLayeredModel_1.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "threeLayeredModel_2.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "threeLayeredModel_3.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "threeLayeredModel_4.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "fourLayeredModel_1.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "fourLayeredModel_2.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "fourLayeredModel_3.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the neural networks:\n",
    "The last step is to train the different neural networks that we have created with the mnist dataset. First, we create an object of myCallback class to detect 99% accuracy condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.4705 - accuracy: 0.8774\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.3034 - accuracy: 0.9153\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.2829 - accuracy: 0.9206\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.2734 - accuracy: 0.9233\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.2666 - accuracy: 0.9256\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.2619 - accuracy: 0.9266\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.2587 - accuracy: 0.9276\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.2554 - accuracy: 0.9292\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.2532 - accuracy: 0.9293\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.2511 - accuracy: 0.9303\n",
      "Two layered model summary:\n",
      "Number of epochs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Best accuracy score: 93.02833080291748\n",
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.2582 - accuracy: 0.9270\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.1146 - accuracy: 0.9662\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0790 - accuracy: 0.9762\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.0587 - accuracy: 0.9819\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.0451 - accuracy: 0.9861\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.0349 - accuracy: 0.9891\n",
      "Epoch 7/10\n",
      "59616/60000 [============================>.] - ETA: 0s - loss: 0.0281 - accuracy: 0.9913\n",
      "Reached accuracy of 99%. Stopping training process!\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0282 - accuracy: 0.9913\n",
      "Three layered model with 128 neurons in hidden layer summary:\n",
      "Number of epochs: [0, 1, 2, 3, 4, 5, 6]\n",
      "Best accuracy score: 99.13166761398315\n",
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.2240 - accuracy: 0.9355\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.0919 - accuracy: 0.9724\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.0610 - accuracy: 0.9817\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.0439 - accuracy: 0.9866\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.0335 - accuracy: 0.9894\n",
      "Epoch 6/10\n",
      "59744/60000 [============================>.] - ETA: 0s - loss: 0.0239 - accuracy: 0.9920\n",
      "Reached accuracy of 99%. Stopping training process!\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.0239 - accuracy: 0.9920\n",
      "Three layered model with 256 neurons in hidden layer summary:\n",
      "Number of epochs: [0, 1, 2, 3, 4, 5]\n",
      "Best accuracy score: 99.20499920845032\n",
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 8s 133us/sample - loss: 0.2021 - accuracy: 0.9406\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.0817 - accuracy: 0.9751\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 0.0512 - accuracy: 0.9838\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.0372 - accuracy: 0.9886\n",
      "Epoch 5/10\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0264 - accuracy: 0.9911\n",
      "Reached accuracy of 99%. Stopping training process!\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.0265 - accuracy: 0.9911\n",
      "Three layered model with 512 neurons in hidden layer summary:\n",
      "Number of epochs: [0, 1, 2, 3, 4]\n",
      "Best accuracy score: 99.11333322525024\n",
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 13s 209us/sample - loss: 0.1831 - accuracy: 0.9456\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 12s 196us/sample - loss: 0.0744 - accuracy: 0.9773\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 12s 204us/sample - loss: 0.0484 - accuracy: 0.9849\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 12s 194us/sample - loss: 0.0344 - accuracy: 0.9889\n",
      "Epoch 5/10\n",
      "59808/60000 [============================>.] - ETA: 0s - loss: 0.0242 - accuracy: 0.9918\n",
      "Reached accuracy of 99%. Stopping training process!\n",
      "60000/60000 [==============================] - 13s 212us/sample - loss: 0.0243 - accuracy: 0.9918\n",
      "Three layered model with 1024 neurons in hidden layer summary:\n",
      "Number of epochs: [0, 1, 2, 3, 4]\n",
      "Best accuracy score: 99.17500019073486\n",
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 14s 229us/sample - loss: 0.1835 - accuracy: 0.9437\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 13s 220us/sample - loss: 0.0794 - accuracy: 0.9743\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 13s 222us/sample - loss: 0.0538 - accuracy: 0.9828\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 13s 217us/sample - loss: 0.0414 - accuracy: 0.9871\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 13s 220us/sample - loss: 0.0346 - accuracy: 0.9892\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 14s 232us/sample - loss: 0.0312 - accuracy: 0.9899\n",
      "Epoch 7/10\n",
      "59744/60000 [============================>.] - ETA: 0s - loss: 0.0252 - accuracy: 0.9923\n",
      "Reached accuracy of 99%. Stopping training process!\n",
      "60000/60000 [==============================] - 14s 232us/sample - loss: 0.0253 - accuracy: 0.9923\n",
      "Four layered model with 512 neurons in first hidden layer and 512 neurons in second hidden layer summary:\n",
      "Number of epochs: [0, 1, 2, 3, 4, 5, 6]\n",
      "Best accuracy score: 99.22666549682617\n",
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 0.1967 - accuracy: 0.9391\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.0850 - accuracy: 0.9737\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0587 - accuracy: 0.9812\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 0.0451 - accuracy: 0.9855\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0377 - accuracy: 0.9879\n",
      "Epoch 6/10\n",
      "59872/60000 [============================>.] - ETA: 0s - loss: 0.0290 - accuracy: 0.9908\n",
      "Reached accuracy of 99%. Stopping training process!\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.0292 - accuracy: 0.9908\n",
      "Four layered model with 256 neurons in first hidden layer and 768 neurons in second hidden layer summary:\n",
      "Number of epochs: [0, 1, 2, 3, 4, 5]\n",
      "Best accuracy score: 99.07833337783813\n",
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 0.2070 - accuracy: 0.9372\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.0911 - accuracy: 0.9723\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0634 - accuracy: 0.9802\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.0495 - accuracy: 0.9842\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.0415 - accuracy: 0.9864\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.0332 - accuracy: 0.9891\n",
      "Epoch 7/10\n",
      "59488/60000 [============================>.] - ETA: 0s - loss: 0.0278 - accuracy: 0.9912\n",
      "Reached accuracy of 99%. Stopping training process!\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.0279 - accuracy: 0.9912\n",
      "Four layered model with 128 neurons in first hidden layer and 896 neurons in second hidden layer summary:\n",
      "Number of epochs: [0, 1, 2, 3, 4, 5, 6]\n",
      "Best accuracy score: 99.11500215530396\n"
     ]
    }
   ],
   "source": [
    "twoLayeredModelHistory = twoLayeredModel.fit(X_train, y_train, epochs = 10, callbacks = [callbacks])\n",
    "print('Two layered model summary:\\nNumber of epochs: {}\\nBest accuracy score: {}'.format(twoLayeredModelHistory.epoch, max(twoLayeredModelHistory.history['accuracy'])*100))\n",
    "\n",
    "threeLayeredModel1History = threeLayeredModel_1.fit(X_train, y_train, epochs = 10, callbacks = [callbacks])\n",
    "print('Three layered model with 128 neurons in hidden layer summary:\\nNumber of epochs: {}\\nBest accuracy score: {}'.format(threeLayeredModel1History.epoch, max(threeLayeredModel1History.history['accuracy'])*100))\n",
    "threeLayeredModel2History = threeLayeredModel_2.fit(X_train, y_train, epochs = 10, callbacks = [callbacks])\n",
    "print('Three layered model with 256 neurons in hidden layer summary:\\nNumber of epochs: {}\\nBest accuracy score: {}'.format(threeLayeredModel2History.epoch, max(threeLayeredModel2History.history['accuracy'])*100))\n",
    "threeLayeredModel3History = threeLayeredModel_3.fit(X_train, y_train, epochs = 10, callbacks = [callbacks])\n",
    "print('Three layered model with 512 neurons in hidden layer summary:\\nNumber of epochs: {}\\nBest accuracy score: {}'.format(threeLayeredModel3History.epoch, max(threeLayeredModel3History.history['accuracy'])*100))\n",
    "threeLayeredModel4History = threeLayeredModel_4.fit(X_train, y_train, epochs = 10, callbacks = [callbacks])\n",
    "print('Three layered model with 1024 neurons in hidden layer summary:\\nNumber of epochs: {}\\nBest accuracy score: {}'.format(threeLayeredModel4History.epoch, max(threeLayeredModel4History.history['accuracy'])*100))\n",
    "\n",
    "fourLayeredModel1History = fourLayeredModel_1.fit(X_train, y_train, epochs = 10, callbacks = [callbacks])\n",
    "print('Four layered model with 512 neurons in first hidden layer and 512 neurons in second hidden layer summary:\\nNumber of epochs: {}\\nBest accuracy score: {}'.format(fourLayeredModel1History.epoch, max(fourLayeredModel1History.history['accuracy'])*100))\n",
    "fourLayeredModel2History = fourLayeredModel_2.fit(X_train, y_train, epochs = 10, callbacks = [callbacks])\n",
    "print('Four layered model with 256 neurons in first hidden layer and 768 neurons in second hidden layer summary:\\nNumber of epochs: {}\\nBest accuracy score: {}'.format(fourLayeredModel2History.epoch, max(fourLayeredModel2History.history['accuracy'])*100))\n",
    "fourLayeredModel3History = fourLayeredModel_3.fit(X_train, y_train, epochs = 10, callbacks = [callbacks])\n",
    "print('Four layered model with 128 neurons in first hidden layer and 896 neurons in second hidden layer summary:\\nNumber of epochs: {}\\nBest accuracy score: {}'.format(fourLayeredModel3History.epoch, max(fourLayeredModel3History.history['accuracy'])*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the neural networks on unseen data:\n",
    "In the following section, we will test all our trained neural networks on our test set X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 72us/sample - loss: 0.2652 - accuracy: 0.9258\n",
      "10000/10000 [==============================] - 1s 51us/sample - loss: 0.0711 - accuracy: 0.9771\n",
      "10000/10000 [==============================] - 1s 50us/sample - loss: 0.0772 - accuracy: 0.9773\n",
      "10000/10000 [==============================] - 1s 69us/sample - loss: 0.0743 - accuracy: 0.9787\n",
      "10000/10000 [==============================] - 1s 93us/sample - loss: 0.0832 - accuracy: 0.9772\n",
      "10000/10000 [==============================] - 1s 92us/sample - loss: 0.0896 - accuracy: 0.9789\n",
      "10000/10000 [==============================] - 1s 71us/sample - loss: 0.1100 - accuracy: 0.9736\n",
      "10000/10000 [==============================] - 1s 56us/sample - loss: 0.1051 - accuracy: 0.9760\n",
      "Observed results:\n",
      "Loss and accuracy of 2 layered neural network-\n",
      "Accuracy: 92.58000254631042\tLoss: 26.516980631351473\n",
      "\n",
      "Loss and accuracy of first 3 layered neural network-\n",
      "Accuracy: 97.71000146865845\tLoss: 7.114940251931548\n",
      "\n",
      "Loss and accuracy of second 3 layered neural network-\n",
      "Accuracy: 97.72999882698059\tLoss: 7.717044354443788\n",
      "\n",
      "Loss and accuracy of third 3 layered neural network-\n",
      "Accuracy: 97.86999821662903\tLoss: 7.433205621260859\n",
      "\n",
      "Loss and accuracy of fourth 3 layered neural network-\n",
      "Accuracy: 97.71999716758728\tLoss: 8.322871014319972\n",
      "\n",
      "Loss and accuracy of first 4 layered neural network-\n",
      "Accuracy: 97.89000153541565\tLoss: 8.962629477282782\n",
      "\n",
      "Loss and accuracy of second 4 layered neural network-\n",
      "Accuracy: 97.35999703407288\tLoss: 11.001411170655338\n",
      "\n",
      "Loss and accuracy of third 4 layered neural network-\n",
      "Accuracy: 97.86999821662903\tLoss: 7.433205621260859\n",
      "\n"
     ]
    }
   ],
   "source": [
    "twoLayerResult = twoLayeredModel.evaluate(X_test, y_test)\n",
    "\n",
    "threeLayerResult1 = threeLayeredModel_1.evaluate(X_test, y_test)\n",
    "threeLayerResult2 = threeLayeredModel_2.evaluate(X_test, y_test)\n",
    "threeLayerResult3 = threeLayeredModel_3.evaluate(X_test, y_test)\n",
    "threeLayerResult4 = threeLayeredModel_4.evaluate(X_test, y_test)\n",
    "\n",
    "fourLayerResult1 = fourLayeredModel_1.evaluate(X_test, y_test)\n",
    "fourLayerResult2 = fourLayeredModel_2.evaluate(X_test, y_test)\n",
    "fourLayerResult3 = fourLayeredModel_3.evaluate(X_test, y_test)\n",
    "\n",
    "print('Observed results:')\n",
    "print('Loss and accuracy of 2 layered neural network-\\nAccuracy: {}\\tLoss: {}\\n'.format(twoLayerResult[1] * 100, twoLayerResult[0] * 100))\n",
    "\n",
    "print('Loss and accuracy of first 3 layered neural network-\\nAccuracy: {}\\tLoss: {}\\n'.format(threeLayerResult1[1] * 100, threeLayerResult1[0] * 100))\n",
    "print('Loss and accuracy of second 3 layered neural network-\\nAccuracy: {}\\tLoss: {}\\n'.format(threeLayerResult2[1] * 100, threeLayerResult2[0] * 100))\n",
    "print('Loss and accuracy of third 3 layered neural network-\\nAccuracy: {}\\tLoss: {}\\n'.format(threeLayerResult3[1] * 100, threeLayerResult3[0] * 100))\n",
    "print('Loss and accuracy of fourth 3 layered neural network-\\nAccuracy: {}\\tLoss: {}\\n'.format(threeLayerResult4[1] * 100, threeLayerResult4[0] * 100))\n",
    "\n",
    "print('Loss and accuracy of first 4 layered neural network-\\nAccuracy: {}\\tLoss: {}\\n'.format(fourLayerResult1[1] * 100, fourLayerResult1[0] * 100))\n",
    "print('Loss and accuracy of second 4 layered neural network-\\nAccuracy: {}\\tLoss: {}\\n'.format(fourLayerResult2[1] * 100, fourLayerResult2[0] * 100))\n",
    "print('Loss and accuracy of third 4 layered neural network-\\nAccuracy: {}\\tLoss: {}\\n'.format(threeLayerResult3[1] * 100, threeLayerResult3[0] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
